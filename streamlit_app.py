# streamlit_app.py
# —Ç–∏—Ç—É–ª–∫–∞ + –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ Release + –≤–∏–±—ñ—Ä –∫-—Å—Ç—ñ –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
# –ø–∏—à—É –ø—Ä–æ—Å—Ç–æ —ñ –ø–æ-—Å—Ç—É–¥–µ–Ω—Ç—Å—å–∫–∏: —â–æ —Ä–æ–±–∏–º–æ —ñ –Ω–∞–≤—ñ—â–æ

import streamlit as st
import os, io, zipfile, requests
from src.data import get_facts, ensure_parquet_cache

st.set_page_config(page_title="–ú–∞–≥—ñ—Å—Ç–µ—Ä—Å—å–∫–∏–π –ø—Ä–æ—î–∫—Ç ‚Äî Olist BI", layout="wide")

# --- –¢–∏—Ç—É–ª–∫–∞
st.title("–ú–∞–≥—ñ—Å—Ç–µ—Ä—Å—å–∫–∏–π –ø—Ä–æ—î–∫—Ç")
st.subheader("–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –±—ñ–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—ñ–≤ (e-commerce Olist)")
st.markdown("""
**–ê–≤—Ç–æ—Ä:** –ü–∞–Ω—Ç—è –ú–∞–∫—Å–∏–º ‚Ä¢ **–§–∞–∫—É–ª—å—Ç–µ—Ç:** –ï–∫–æ–Ω–æ–º—ñ—á–Ω–∏–π ‚Ä¢ **–†—ñ–∫:** 2025

–¶–µ –ø—Ä–æ—Å—Ç–∏–π, –∞–ª–µ –∫–æ—Ä–∏—Å–Ω–∏–π BI-—ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: –¥–∏–≤–∏–º–æ—Å—å KPI, –¥–æ—Å—Ç–∞–≤–∫—É (SLA), –æ–ø–ª–∞—Ç–∏, –≤—ñ–¥–≥—É–∫–∏, —Å–µ–≥–º–µ–Ω—Ç–∏ RFM,
–∫–æ—à–∏–∫–∏ —Ç–æ–≤–∞—Ä—ñ–≤ (Market Basket), **ROI-–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä**, —ñ –ø—Ä–∞—Ü—é—î–º–æ –∑ **AI-–∞–≥–µ–Ω—Ç–æ–º**.
""")

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–∂–µ—Ä–µ–ª–∞ –¥–∞–Ω–∏—Ö
RELEASE_ZIP = st.secrets.get("DATA_RELEASE_ZIP", "") 
DATA_DIR = "data"

def ensure_data():
    """–°–∫–∞—á—É—é zip —ñ–∑ Release –ª–∏—à–µ —è–∫—â–æ –≤ –ø–∞–ø—Ü—ñ data/ –Ω–µ–º–∞—î CSV.
    –†–æ–±–ª—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏, —â–æ–± –Ω–µ –∑–ª–æ–≤–∏—Ç–∏ –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π URL / –ø–æ–≥–∞–Ω–∏–π ZIP.
    """
    os.makedirs(DATA_DIR, exist_ok=True)

    # —è–∫—â–æ –≤–∂–µ —î CSV ‚Äî –Ω—ñ—á–æ–≥–æ –Ω–µ —Ä–æ–±–∏–º–æ
    if any(fn.endswith(".csv") for fn in os.listdir(DATA_DIR)):
        return

    if not RELEASE_ZIP:
        st.warning("–î–∞–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —ñ DATA_RELEASE_ZIP –Ω–µ –∑–∞–¥–∞–Ω–æ –≤ Secrets.")
        return

    if not (RELEASE_ZIP.startswith("http://") or RELEASE_ZIP.startswith("https://")):
        st.warning("DATA_RELEASE_ZIP –≤–∏–≥–ª—è–¥–∞—î –Ω–µ —è–∫ URL. –ü–µ—Ä–µ–≤—ñ—Ä –∑–Ω–∞—á–µ–Ω–Ω—è –≤ Secrets.")
        return

    with st.spinner("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—é Olist dataset –∑ Release‚Ä¶"):
        try:
            r = requests.get(RELEASE_ZIP, allow_redirects=True, timeout=60)
            r.raise_for_status()
            with zipfile.ZipFile(io.BytesIO(r.content)) as z:
                z.extractall(DATA_DIR)
        except (requests.RequestException, zipfile.BadZipFile) as e:
            st.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏/—Ä–æ–∑–ø–∞–∫—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ –∑ Release: {e}")

# –ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–∞–Ω—ñ —Ç–∞ –ø–æ–±—É–¥—É–≤–∞—Ç–∏ Parquet-–∫–µ—à
try:
    ensure_data()
except Exception as e:
    # –¥–æ–¥–∞—Ç–∫–æ–≤–∏–π –∑–∞–ø–æ–±—ñ–∂–Ω–∏–∫, —â–æ–± –≥–æ–ª–æ–≤–Ω–∞ –Ω–µ –ø–∞–¥–∞–ª–∞
    st.warning(f"–ù–µ–æ—á—ñ–∫—É–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö: {e}")

ensure_parquet_cache(DATA_DIR)  # –ø—Ä–∏—Å–∫–æ—Ä—é–≤–∞—á —á–∏—Ç–∞–Ω–Ω—è (Parquet-–∫–µ—à)

# --- –ö–æ–Ω—Ç—Ä–æ–ª –≤–∏–±—ñ—Ä–∫–∏ (–∫-—Å—Ç—å —Ä—è–¥–∫—ñ–≤)
# –Ñ–î–ò–ù–ï –º—ñ—Å—Ü–µ, –¥–µ –∑–∞–¥–∞—î—Ç—å—Å—è –ª—ñ–º—ñ—Ç. –Ü–Ω—à—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –ù–ï –º—ñ—Å—Ç—è—Ç—å –≤–ª–∞—Å–Ω–∏—Ö –ª—ñ–º—ñ—Ç—ñ–≤.
if "max_orders" not in st.session_state:
    st.session_state["max_orders"] = 10_000  # –¥–µ—Ñ–æ–ª—Ç –¥–ª—è —Ö–º–∞—Ä–∏; –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –º–æ–∂–µ –∑–º—ñ–Ω–∏—Ç–∏

st.markdown("### –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤–∏–±—ñ—Ä–∫–∏")
max_rows = st.number_input(
    "–ö-—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ 10 000 –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ —É —Ö–º–∞—Ä—ñ)",
    min_value=1_000, max_value=200_000, step=1_000, value=st.session_state["max_orders"],
    help="–ú–µ–Ω—à–µ ‚Äî —à–≤–∏–¥—à–µ. –ë—ñ–ª—å—à–µ ‚Äî –¥–µ—Ç–∞–ª—å–Ω—ñ—à–µ, –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ."
)
st.session_state["max_orders"] = int(max_rows)

# --- –ö–µ—à–æ–≤–∞–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–∫—Ç—ñ–≤ (—à–≤–∏–¥—à–µ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–∏—Ö –≤—ñ–¥–∫—Ä–∏—Ç—Ç—è—Ö)
@st.cache_data(show_spinner=False)
def load_facts_cached(data_dir: str, max_orders: int | None):
    # —è–∫—â–æ max_orders=None -> get_facts –ø–æ–≤–µ—Ä—Ç–∞—î –≤—Å—ñ –¥–∞–Ω—ñ (—Ü–µ –≤–∞–∂–ª–∏–≤–æ!)
    return get_facts(data_dir, max_orders=max_orders)

# --- –ú—ñ–Ω—ñ-–¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ (—â–æ–± –±–∞—á–∏—Ç–∏, —â–æ –¥–∞–Ω—ñ –ø—Ä–∞—Ü—é—é—Ç—å –∑ –æ–±—Ä–∞–Ω–∏–º –ª—ñ–º—ñ—Ç–æ–º)
facts = load_facts_cached(DATA_DIR, st.session_state.get("max_orders"))

if facts.empty:
    st.error("–î–∞–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ. –ü–µ—Ä–µ–≤—ñ—Ä, —á–∏ —î CSV —É –ø–∞–ø—Ü—ñ `data/` –∞–±–æ —á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∫–∞–∑–∞–Ω–æ DATA_RELEASE_ZIP —É Secrets.")
else:
    c1, c2, c3 = st.columns(3)
    c1.metric("–ó–∞–º–æ–≤–ª–µ–Ω—å —É –≤–∏–±—ñ—Ä—Ü—ñ", f"{facts['order_id'].nunique():,}")
    c2.metric("On-time, %", f"{facts['on_time'].mean()*100:,.1f}%")
    c3.metric("–í–∏—Ä—É—á–∫–∞ (BrL)", f"{facts['gross_revenue'].sum():,.0f}")
    st.caption(f"–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π –ª—ñ–º—ñ—Ç: {st.session_state['max_orders']:,} –∑–∞–ø–∏—Å—ñ–≤.")

# --- –ö–Ω–æ–ø–∫–∏-–Ω–∞–≤—ñ–≥–∞—Ü—ñ—è
st.markdown("### –ü–µ—Ä–µ–π–¥—ñ—Ç—å –¥–æ —Å—Ç–æ—Ä—ñ–Ω–æ–∫ –∞–Ω–∞–ª—ñ–∑—É")

def page_if_exists(path: str, label: str, **kwargs):
    import os
    if os.path.exists(path):
        st.page_link(path, label=label, **kwargs)
    else:
        st.caption(f"‚ö†Ô∏è {label} ‚Äî —Ñ–∞–π–ª –≤—ñ–¥—Å—É—Ç–Ω—ñ–π ({path})")

cols = st.columns(3)
with cols[0]:
    page_if_exists("pages/0_AI_Agent.py", label="ü§ñ AI-–ê–≥–µ–Ω—Ç")
    page_if_exists("pages/1_KPI_Trends.py", label="üìà KPI & Trends")
    page_if_exists("pages/2_SLA_Delivery.py", label="üöö Delivery")
with cols[1]:
    page_if_exists("pages/3_Payments.py", label="üí≥ Payments")
    page_if_exists("pages/4_Reviews.py", label="‚≠ê Reviews")
    page_if_exists("pages/5_RFM.py", label="üë• RFM")
with cols[2]:
    page_if_exists("pages/7_ROI.py", label="üíµ ROI / Unit Economics")
    page_if_exists("pages/8_Geo_SLA.py", label="üåé Geo-SLA")
    page_if_exists("pages/9_Delay_Risk.py", label="‚ö†Ô∏è –†–∏–∑–∏–∫ –ø—Ä–æ—Å—Ç—Ä–æ—á–∫–∏", disabled=False)
    
    
